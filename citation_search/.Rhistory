install.packages("fulltext")
?fulltext-package
?fulltext-package
library(fulltext)
?fulltext-package
?fulltext
library(fulltext)
?fulltext
?is.na
DF <- data.frame(x = c(1, 2, 3), y = c(0, 10, NA))
na.omit(DF)
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(dplyr)
# load in categorization data
abstracts_df<-read.csv("dataset_categorization.csv", colClasses = "character") %>%
select(id, abstract)
# Select a long abstract I found from preloaded dataset of all ADC abstracts. Somewhere in this abstract there is a reference to a connected publication.
sample_abstract <- abstracts_df[64,2]
sample_abstract
publication_regex <- "[^.!?]*publi(?:sh|cation)[^.!?]*"
str_extract(abstract, publication_regex)
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(dplyr)
# load in categorization data
abstracts_df<-read.csv("dataset_categorization.csv", colClasses = "character") %>%
select(id, abstract)
# Select a long abstract I found from preloaded dataset of all ADC abstracts. Somewhere in this abstract there is a reference to a connected publication.
sample_abstract <- abstracts_df[64,2]
sample_abstract
publication_regex <- "[^.!?]*publi(?:sh|cation)[^.!?]*"
str_extract(sample_abstract, publication_regex)
# You can run `str_extract` on a list too
str_extract(c("irrelevant abstract", sample_abstract, "This is an oceanography dataset. It was used in a publication."), publication_regex)
regex <- "[^.!?]*(?:article|paper|journal|publi(?:sh|cation))[^.!?]*"
abstracts_extracted <- abstracts_df %>%
mutate(citation_reference=str_extract(abstract, regex))
na.omit(abstracts_extracted)
View(na.omit(abstracts_extracted))
head(na.omit(abstracts_extracted))
regex <- "[^.!?]*(?:article|paper|journal|publi(?:sh|cation))[^.!?]*"
abstracts_extracted <- abstracts_df %>%
mutate(citation_reference=str_extract(abstract, regex)) %>%
na.omit()
head(abstracts_extracted)
?head()
?options
head(abstracts_extracted, options = list(scrollX=TRUE, width=10))
View(head(abstracts_extracted, options = list(scrollX=TRUE, width=10)))
#' Search for citations in text across all APIs
#'
#' @param identifiers a vector of identifiers to be searched for
#'
#' @return tibble of matching dataset and publication identifiers
#' @export
#' @examples
#' identifiers <- c("10.18739/A22274", "10.18739/A2D08X", "10.5063/F1T151VR")
#' result <- citation_search_plos(identifiers)
citation_search <- function(identifiers) {
if (any(!grepl("10\\.|urn:uuid", identifiers))){
warning(call. = FALSE, "One or more identifiers does not appear to be a DOI or uuid")
}
results <- rbind(citation_search_plos(identifiers),
citation_search_bmc(identifiers)
)
}
#' Search for citations in PLOS
#'
#' This function searches for citations in PLOS. Requests are throttled
#' at one identifier every 6 seconds so as to not overload the PLOS
#' API.
#'
#' @param identifiers a vector of identifiers to be searched for
#'
#' @return tibble of matching dataset and publication identifiers
#' @export
#' @importFrom rplos searchplos
#' @examples
#'
#' identifiers <- c("10.18739/A22274", "10.18739/A2D08X", "10.5063/F1T151VR")
#' result <- citation_search_plos(identifiers)
#'
citation_search_plos <- function(identifiers) {
if (length(identifiers) > 1){
message(paste0("Your result will take ~", length(identifiers)*6 ," seconds to return,
since this function is rate limited to one call every 6 seconds."))
}
identifiers <- check_identifiers(identifiers)
# search for identifier
results <- lapply(identifiers, function(x){
Sys.sleep(6)
v <- rplos::searchplos(q = x,
fl = c("id","title"),
limit = 1000)
return(v)
}
)
plos_results <- list()
# assign dataset identifier to each result
for (i in 1:length(results)){
if (results[[i]]$meta$numFound == 0 | is.null(results[[i]])){
plos_results[[i]] <- data.frame(id = NA,
dataset_id = identifiers[i],
title = NA)
}
else if (results[[i]]$meta$numFound > 0){
plos_results[[i]] <- results[[i]]$data
plos_results[[i]]$dataset_id <- identifiers[i]
}
}
# bind resulting tibbles
plos_results <- do.call(rbind, plos_results)
names(plos_results)[which(names(plos_results) == "id")] <- "article_id"
names(plos_results)[which(names(plos_results) == "title")] <- "article_title"
return(plos_results)
}
#' Search for citations in BMC
#'
#' This function searches for citations in BMC. It requires that an API key
#' be obtained from [Springer](https://dev.springernature.com/) and set using
#' `scythe_set_key()`. Requests are throttled at one identifier every second
#' so as to not overload the PLOS API.
#'
#' @param identifiers a vector of identifiers to be searched for
#'
#' @return tibble of matching dataset and publication identifiers
#' @importFrom jsonlite fromJSON
#' @importFrom curl curl
#' @export
#' @examples
#'
#' identifiers <- c("10.18739/A22274", "10.18739/A2D08X", "10.5063/F1T151VR")
#' result <- citation_search_bmc(identifiers)
#'
citation_search_bmc <- function(identifiers) {
if (length(identifiers) > 1){
message(paste0("Your result will take ~", length(identifiers)*1 ," seconds to return, since this function is rate limited to one call every second."))
}
identifiers <- check_identifiers(identifiers)
tmp <- keyring::key_get("bmc_key", keyring = "scythe")
results <- list()
for (i in 1:length(identifiers)) {
Sys.sleep(1)
results[[i]] <- jsonlite::fromJSON(curl::curl(paste0("http://api.springernature.com/meta/v2/json?q=",
identifiers[i],
"&api_key=",
tmp,
"&p=100")
))
}
# assign dataset identifier to each result
bmc_results <- list()
for (i in 1:length(results)){
if (as.numeric(results[[i]]$result$total) == 0 | is.null(results[[i]])){
bmc_results[[i]] <- data.frame(article_id = NA,
dataset_id = identifiers[i],
article_title = NA)
}
else if (as.numeric(results[[i]]$result$total) > 0){
bmc_results[[i]] <- data.frame(article_id = NA,
dataset_id = NA,
article_title = NA)
bmc_results[[i]]$article_id <- results[[i]]$records$identifier
bmc_results[[i]]$article_title <- results[[i]]$records$title
bmc_results[[i]]$dataset_id <- identifiers[i]
}
}
# bind resulting tibbles
bmc_results <- do.call(rbind, bmc_results)
# remove doi: prefix for consistency
bmc_results$article_id <- gsub("doi:", "", bmc_results$article_id)
return(bmc_results)
}
#' Search for citations in Scopus
#'
#' This function searches for citations in Scopus. Requests are throttled
#' 9 requests/second so as to not overload the Scopus API.
#'
#' @param identifiers a vector of identifiers to be searched for
#'
#' @return tibble of matching dataset and publication identifiers
#' @export
#' @importFrom rscopus scopus_search
#' @examples
#'
#' identifiers <- c("10.18739/A22274", "10.18739/A2D08X", "10.5063/F1T151VR")
#' result <- citation_search_scopus(identifiers)
#'
citation_search_scopus <- function(identifiers) {
check_identifiers(identifiers)
if (length(identifiers) > 8){
message(paste0("Your result will take ~", length(identifiers)/9 ," seconds to return, since this function is rate limited to 9 calls per second."))
}
tmp <- keyring::key_get("scopus_key", keyring = "scythe")
results <- list()
for (i in 1:length(identifiers)) {
Sys.sleep(0.12)
results[[i]] <-
fromJSON(curl(paste0("https://api.elsevier.com/content/search/scopus?query=ALL:", identifiers[i], paste("&APIKey=",tmp, sep=""))))
}
# initialize df for storing results in orderly fashion
scopus_results <- data.frame(article_id = character(),
article_title = character(),
dataset_id = character())
# extract relevant information from raw results
for (i in 1:length(results)) {
num_citations <- as.numeric(results[[i]][["search-results"]][["opensearch:totalResults"]])
article_id <- results[[i]][["search-results"]][["entry"]][["prism:doi"]]
article_title <- results[[i]][["search-results"]][["entry"]][["dc:title"]]
dataset_id <- rep(identifiers[i], num_citations)
scopus_results <- rbind(scopus_results, data.frame(article_id,article_title,dataset_id))
}
# clean up dois
scopus_results <- scopus_results %>%
mutate(dataset_id = gsub("ALL:", "", dataset_id))
return(scopus_results)
}
# Check identifiers to remove characters that interfere with query strings
check_identifiers <- function(identifiers){
if (any(!grepl("10\\.|urn:uuid", identifiers))){
warning(call. = FALSE,
"One or more identifiers does not appear to be a DOI or uuid",
immediate. = TRUE)
}
if (any(grepl("doi:|urn:uuid", identifiers))){
identifiers <- gsub("(doi:)|(urn:uuid:)", "", identifiers)
}
if (any(grepl(":", identifiers))){
identifiers <- gsub(":", "", identifiers) # handle other problematic colons
}
return(identifiers)
}
citation_search_scopus(c("10.18739/A22274", "10.18739/A2D08X", "10.5063/F1T151VR"))
library(jsonlite)
citation_search_scopus(c("10.18739/A22274", "10.18739/A2D08X", "10.5063/F1T151VR"))
library(curl)
citation_search_scopus(c("10.18739/A22274", "10.18739/A2D08X", "10.5063/F1T151VR"))
library(dplyr)
citation_search_scopus(c("10.18739/A22274", "10.18739/A2D08X", "10.5063/F1T151VR"))
citation_list<-citation_search_scopus(c("10.18739/A22274", "10.18739/A2D08X", "10.5063/F1T151VR"))
#' @param citation_list (data.frame) data.frame of citation pairs containing variables article_id and dataset_id
#' @param path (char) path to write JSON citation pairs to
#'
#' @export
#'
#' @examples
#' pairs <- data.frame(article_id = "10.1371/journal.pone.0213037",
#'                     dataset_id = "10.18739/A22274")
#'
#' write_citation_pairs(citation_list = pairs, path = "citation_pairs.json")
write_citation_pairs <- function(citation_list, path) {
if (any(!(c("article_id", "dataset_id") %in% names(citation_list)))){
stop(.call = FALSE, "citations_list data.frame does not contain variables article_id and/or dataset_id")
}
# write list of citations to bib format
bib <- rcrossref::cr_cn(dois = citation_list$article_id, format = "bibtex")
t <- tempfile()
writeLines(unlist(bib), t)
# import as a dataframe
df <- bib2df::bib2df(t)
# assign article_id to data.frame
df$dataset_id <- citation_list$dataset_id
# rename for database ingest
cit_full <- df %>%
dplyr::rename(target_id = .data$dataset_id,
source_id = .data$DOI,
source_url = .data$URL,
origin = .data$AUTHOR,
title = .data$TITLE,
publisher = .data$PUBLISHER,
journal = .data$JOURNAL,
volume = .data$VOLUME,
page = .data$PAGES,
year_of_publishing = .data$YEAR) %>%
dplyr::select(.data$target_id, .data$source_id, .data$source_url, .data$origin, .data$title, .data$publisher, .data$journal, .data$volume, .data$page, .data$year_of_publishing) %>%
dplyr::mutate(id = NA, report = NA, metadata = NA, link_publication_date = Sys.Date()) #%>%
#dplyr::mutate(publisher = ifelse(.data$publisher == "Elsevier {BV", "Elsevier", "Copernicus"))
write_json(cit_full, path)
}
citation_list
citation_list<-citation_list[,c(1,3)]
citation_list
getwd()
setwd("Documents/GitHub")
write_citation_pairs(citation_list, path="scopus_cit_6_11.json")
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(dplyr)
# load in categorization data
abstracts_df<-read.csv("dataset_categorization.csv", colClasses = "character") %>%
select(url, id, abstract)
publication_regex <- "[^.!?]*publi(?:sh|cation)[^.!?]*"
str_extract(sample_abstract, publication_regex)
# You can run `str_extract` on a list too
str_extract(c("irrelevant abstract", sample_abstract, "This is an oceanography dataset. It was used in a publication.", "I wanted this data for publication. Then i published it"), publication_regex)
# You can run `str_extract` on a list too
str_extract_all(c("irrelevant abstract", sample_abstract, "This is an oceanography dataset. It was used in a publication.", "I wanted this data for publication. Then i published it"), publication_regex)
publication_regex <- "[^.!?]*publi(?:sh|cation)[^.!?]*"
str_extract(sample_abstract, publication_regex)
# You can run `str_extract` on a list too
str_extract_all(c("irrelevant abstract", sample_abstract, "This is an oceanography dataset. It was used in a publication.", "I wanted this data for publication. Then i published it"), publication_regex)
getwd()
setwd("/Users/samet/Documents/R/citation_search")
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(dplyr)
# load in categorization data
abstracts_df<-read.csv("dataset_categorization.csv", colClasses = "character") %>%
select(url, id, abstract)
sample_abstract <- abstracts_df[64,3]
sample_abstract
publication_regex <- "[^.!?]*publi(?:sh|cation)[^.!?]*"
str_extract(sample_abstract, publication_regex)
# You can run `str_extract` on a list too
str_extract_all(c("irrelevant abstract", sample_abstract, "This is an oceanography dataset. It was used in a publication.", "Conta. Then i published it"), publication_regex)
regex <- "[^.!?]*(?:article|paper|journal|publi(?:sh|cation))[^.!?]*"
# This code creates a df including only dois & abstracts that triggered the regex
# and adds a column with the extracted text.
abstracts_extracted <- abstracts_df %>%
mutate(citation_reference=str_extract_all(abstract, regex)) %>%
na.omit()
write.csv(abstracts_extracted, file="adc_publication_keyword_search_all.csv")
abstracts_extracted
View(abstracts_extracted)
paste(str_extract_all("blah blah publication. blah blah journal.", regex))
blurb<-paste(str_extract_all("blah blah publication. blah blah journal.", regex))
blurb
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(dplyr)
# load in categorization data
abstracts_df<-read.csv("dataset_categorization.csv", colClasses = "character") %>%
select(url, id, abstract)
sample_abstract <- abstracts_df[64,3]
sample_abstract
publication_regex <- "[^.!?]*publi(?:sh|cation)[^.!?]*"
str_extract(sample_abstract, publication_regex)
# You can run `str_extract` on a list too
str_extract_all(c("irrelevant abstract", sample_abstract, "This is an oceanography dataset. It was used in a publication.", "Conta. Then i published it"), publication_regex)
regex <- "[^.!?]*(?:article|paper|journal|publi(?:sh|cation))[^.!?]*"
# This code creates a df including only dois & abstracts that triggered the regex
# and adds a column with the extracted text.
abstracts_extracted <- abstracts_df %>%
mutate(citation_reference=paste(str_extract_all(abstract, regex))) %>%
na.omit()
write.csv(abstracts_extracted, file="adc_publication_keyword_search_all.csv")
?compact()
test_df<-abstracts_df.head(10)
test_df<-head(abstracts_df, 10)
test_df
View(test_df)
regex <- "[^.!?]*(?:article|paper|journal|publi(?:sh|cation))[^.!?]*"
# This code creates a df including only dois & abstracts that triggered the regex
# and adds a column with the extracted text.
abstracts_extracted <- abstracts_df %>%
mutate(citation_reference=paste(str_extract_all(abstract, regex))) %>%
na.omit() %>%
compact()
library(purrr)
?drop
character(0)
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(dplyr)
# load in categorization data
abstracts_df<-read.csv("dataset_categorization.csv", colClasses = "character") %>%
select(url, id, abstract)
sample_abstract <- abstracts_df[64,3]
sample_abstract
publication_regex <- "[^.!?]*publi(?:sh|cation)[^.!?]*"
str_extract(sample_abstract, publication_regex)
# You can run `str_extract` on a list too
str_extract_all(c("irrelevant abstract", sample_abstract, "This is an oceanography dataset. It was used in a publication.", "Conta. Then i published it"), publication_regex)
regex <- "[^.!?]*(?:article|paper|journal|publi(?:sh|cation))[^.!?]*"
# This code creates a df including only dois & abstracts that triggered the regex
# and adds a column with the extracted text.
abstracts_extracted <- abstracts_df %>%
mutate(citation_reference=paste(str_extract_all(abstract, regex))) %>%
filter(citation_reference != character(0))
?filter
"d" == "d"
"blah" != character(0)
"blah" != "blee"
1 != 3
typeof(abstracts_extracted$citation_reference)
?str_detect
str_detect(fruit, "b")
str_detect("fruit", "b")
str_detect("fruit", "\w")
filter(length("a","aa", character())>0)
filter(length(character())>0)
regex <- "[^.!?]*(?:article|paper|journal|publi(?:sh|cation))[^.!?]*"
# This code creates a df including only dois & abstracts that triggered the regex
# and adds a column with the extracted text.
abstracts_extracted <- abstracts_df %>%
mutate(citation_reference=paste(str_extract_all(abstract, regex))) %>%
filter(length(citation_reference) > 0)
write.csv(abstracts_extracted, file="adc_publication_keyword_search_all.csv")
View(abstracts_extracted)
View(abstracts_extracted %>% filter(length(citation_reference) > 1))
length(character(0))
View(abstracts_extracted[nchar(abstracts_extracted$citation_reference)>0])
View(abstracts_extracted[nchar(abstracts_extracted$citation_reference)>0],)
View(abstracts_extracted[!(abstracts_extracted$citation_reference==character(0)),]
)
abstracts_extracted$citation_reference
regex <- "[^.!?]*(?:article|paper|journal|publi(?:sh|cation))[^.!?]*"
# This code creates a df including only dois & abstracts that triggered the regex
# and adds a column with the extracted text.
abstracts_extracted <- abstracts_df %>%
mutate(citation_reference=paste(str_extract_all(abstract, regex))) %>%
filter(citation_reference != "character(0)")
write.csv(abstracts_extracted, file="adc_publication_keyword_search_all.csv")
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(dplyr)
# load in categorization data
abstracts_df<-read.csv("dataset_categorization.csv", colClasses = "character") %>%
select(url, id, abstract)
head(abstracts_extracted)
head(abstracts_extracted$citation_reference)
regex <- "[^.!?]*(?:article|paper|journal|publi(?:sh|cation))[^.!?]*"
# This code creates a df including only dois & abstracts that triggered the regex
# and adds a column with the extracted text.
abstracts_extracted <- abstracts_df %>%
mutate(citation_reference=paste(str_extract_all(abstract, regex))) %>%
filter(citation_reference != "character(0)")
head(abstracts_extracted$citation_reference)
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
library(dplyr)
# load in categorization data
abstracts_df<-read.csv("dataset_categorization.csv", colClasses = "character") %>%
select(url, id, abstract)
sample_abstract <- abstracts_df[64,3]
sample_abstract
publication_regex <- "[^.!?]*publi(?:sh|cation)[^.!?]*"
str_extract(sample_abstract, publication_regex)
# You can run `str_extract` on a list too
str_extract_all(c("irrelevant abstract", sample_abstract, "This is an oceanography dataset. It was used in a publication.", "We collected this data. The data was published"), publication_regex)
regex <- "[^.!?]*(?:article|paper|journal|publi(?:sh|cation))[^.!?]*"
# This code creates a df including only dois & abstracts that triggered the regex
# and adds a column with the extracted text.
abstracts_extracted <- abstracts_df %>%
mutate(citation_reference=paste(str_extract_all(abstract, regex))) %>%
filter(citation_reference != "character(0)")
